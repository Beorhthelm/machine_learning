{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling categorical data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3dZEp05rN8tN"
   },
   "source": [
    "In this project I am going to work with the following dataset from Kaggle:\n",
    "\n",
    "https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "Suppose that a company working with Big Data and Data Science wants to hire data scientists among people who have successfully passed some courses conducted by the company. Many people sign up for their training. The company wants to focus of the candidates who really want to work for them after training. Information related to demographics, education, experience is provided by the candidates via a sign-up form.\n",
    "\n",
    "This dataset is designed to understand the factors that lead a person to leave current job which is useful for HR researches. Based on the provided data, you are going to predict whether a candidate is looking for a job change.\n",
    "\n",
    "The whole data is divided into train and test parts. Data contains several categorical features – they need to be encoded.\n",
    "\n",
    "## Feature description\n",
    "\n",
    "- `enrollee_id`: Unique ID for a candidate\n",
    "- `city`: City code\n",
    "- `city_development_index`: Developement index of the city (scaled)\n",
    "- `gender`: Gender of a candidate\n",
    "- `relevent_experience`: Relevant experience of a candidate\n",
    "- `enrolled_university`: Type of University course enrolled in if any\n",
    "- `education_level`: Education level of a candidate\n",
    "- `major_discipline`: Education major discipline of a candidate\n",
    "- `experience`: Candidate total experience in years\n",
    "- `company_size`: Number of employees in a current employer's company\n",
    "- `company_type`: Type of a current employer\n",
    "- `last_new_job`: Difference in years between previous and current jobs\n",
    "- `training_hours`: training hours completed\n",
    "- `target`: 0 – Not looking for job change, 1 – Looking for a job change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/aug_train.csv')\n",
    "test = pd.read_csv('data/aug_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-riW7UN88QB0"
   },
   "source": [
    "Before modifying the features, let's study our dataframe a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28120</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31820</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>2</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Early Stage Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4277</td>\n",
       "      <td>city_71</td>\n",
       "      <td>0.884</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>Part time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3379</td>\n",
       "      <td>city_159</td>\n",
       "      <td>0.843</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10821</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender   \n",
       "0        28120   city_16                   0.910    NaN  \\\n",
       "1        31820   city_21                   0.624    NaN   \n",
       "2         4277   city_71                   0.884   Male   \n",
       "3         3379  city_159                   0.843   Male   \n",
       "4        10821   city_16                   0.910   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level   \n",
       "0  Has relevent experience       no_enrollment     High School  \\\n",
       "1   No relevent experience       no_enrollment         Masters   \n",
       "2  Has relevent experience    Part time course        Graduate   \n",
       "3  Has relevent experience       no_enrollment         Masters   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size         company_type last_new_job   \n",
       "0              NaN         19      100-500              Pvt Ltd            2  \\\n",
       "1             STEM          2        50-99  Early Stage Startup            1   \n",
       "2             STEM        >20          NaN                  NaN            2   \n",
       "3             STEM        >20          <10              Pvt Ltd           >4   \n",
       "4             STEM          6          NaN                  NaN            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              20     0.0  \n",
       "1              10     1.0  \n",
       "2               6     1.0  \n",
       "3              56     0.0  \n",
       "4              15     0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     10\n",
       "int64       2\n",
       "float64     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BaEwQjRg6Tj_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                    4508\n",
       "relevent_experience          0\n",
       "enrolled_university        386\n",
       "education_level            460\n",
       "major_discipline          2813\n",
       "experience                  65\n",
       "company_size              5938\n",
       "company_type              6140\n",
       "last_new_job               423\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qxc_ZFXyQ2lc"
   },
   "source": [
    "Some features have a relatively small number of missing values. For instance, `'experience'` has only 65 missing values in the train data. Replacing these missing values with a special category might introduce bias to the data. However, since the number of missing values is not so big, it might be OK.\n",
    "\n",
    "So, let's replace missing values in `'experience'` feature with a category -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dWv8Npro6VA1"
   },
   "outputs": [],
   "source": [
    "train.experience = train.experience.fillna(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Od7G5iQ2ZVNB"
   },
   "source": [
    "`'education_level'` is an ordinal feature. Let's apply the following mapping for the values of `'education_level'` feature:\n",
    "\n",
    "* `np.nan` -> -1\n",
    "* `'Primary School'` -> 0\n",
    "* `'High School'` -> 1\n",
    "* `'Graduate'` -> 2\n",
    "* `'Masters'` -> 3\n",
    "* `'Phd'` -> 4\n",
    "\n",
    "So, at the same time I impute missing values in `'education_level'` with a new category -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BKDebpQX6WL7"
   },
   "outputs": [],
   "source": [
    "map_education = {\n",
    "    np.nan: -1,\n",
    "    'Primary School': 0,\n",
    "    'High School': 1,\n",
    "    'Graduate': 2,\n",
    "    'Masters': 3,\n",
    "    'Phd': 4\n",
    "}\n",
    "\n",
    "train.education_level = train.education_level.map(map_education)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NAi9S-YBrOlY"
   },
   "source": [
    "Feature `'relevent_experience'` is a binary feature. It has no missing values, which makes its encoding pretty easy.\n",
    "\n",
    "Let's encode this feature with the following mapping:\n",
    "\n",
    "*   `\"No relevent experience\"` -> 0\n",
    "*   `\"Has relevent experience\"` -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l5uTrVl36XjM"
   },
   "outputs": [],
   "source": [
    "map_relevent_experience = {\n",
    "    \"No relevent experience\": 0,\n",
    "    \"Has relevent experience\": 1\n",
    "}\n",
    "\n",
    "train.relevent_experience = train.relevent_experience.map(map_relevent_experience)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv-zgcIDtzqR"
   },
   "source": [
    "In our case, `'gender'` is a nominal feature (notice that it is not a binary feature cause it contains three categories + NaNs). I will use One-Hot encoding to encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7IGy0CV96Y8Q"
   },
   "outputs": [],
   "source": [
    "df_gender_tr = pd.get_dummies(train.gender)\n",
    "df_gender_tr.columns = ['gender-' + column for column in df_gender_tr.columns]\n",
    "\n",
    "train = pd.concat([train, df_gender_tr], axis=1)\n",
    "train.drop('gender', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IJx2G8ZQv_Hy"
   },
   "source": [
    "Let's also perform One-Hot encoding for the feature `'enrolled_university'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TrHkhli66aPP"
   },
   "outputs": [],
   "source": [
    "df_enrolled_university_tr = pd.get_dummies(train.enrolled_university)\n",
    "df_enrolled_university_tr.columns = ['enrolled_university-' + column for column in df_enrolled_university_tr.columns]\n",
    "\n",
    "train = pd.concat([train, df_enrolled_university_tr], axis=1)\n",
    "train.drop('enrolled_university', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UBervQFY9N7K"
   },
   "source": [
    "Let's encode feature `'city'` using frequency encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Co-kiLuc6bO6"
   },
   "outputs": [],
   "source": [
    "map_city = train.city.value_counts()\n",
    "\n",
    "train.city = train.city.map(map_city)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ksJw_j-M9XCC"
   },
   "source": [
    "Let's encode feature `'last_new_job'` with target encoding with no modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tmZgKA1_6caQ"
   },
   "outputs": [],
   "source": [
    "train.last_new_job.fillna(-1, inplace=True)\n",
    "\n",
    "map_last_new_job = train.groupby('last_new_job').target.mean()\n",
    "train.last_new_job = train.last_new_job.map(map_last_new_job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TyIVTPEY9eLb"
   },
   "source": [
    "Let's encode feature `'experience'` with M-estimate encoding. In this case each category of `'experience'` will be mapped according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) + m\\times y_{\\text{mean}}}{\\text{count}\\left(j, x_{ij}\\right) + m}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $x_{ij}$ is a category being encoded,\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $m$ is a parameter.\n",
    "\n",
    "Let's set $m = 0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cbihpCuH6dxL"
   },
   "outputs": [],
   "source": [
    "target_exp = train.groupby('experience').target.sum()\n",
    "count_exp = train.groupby('experience').target.count()\n",
    "y_mean = train.target.mean()\n",
    "m = 0.5\n",
    "\n",
    "map_experience = (target_exp + m * y_mean) / (count_exp + m)\n",
    "train.experience = train.experience.map(map_experience)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P0eCGRxLLJ-Y"
   },
   "source": [
    "Let's encode feature `'major_discipline'` with Leave-One-Out encoding. This technique is similar to target encoding, but here while computing the encoding for a particular observation, we exclude it from the target encoding formula. Therefore a category $x_{ij}$ for the $i$-th observation will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) - y_i}{\\text{count}\\left(j, x_{ij}\\right) - 1}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $y_i$ is a target value of the $i$-th observation\n",
    "\n",
    "In this method the same category can be encoded differently for different observations. Thus, after encoding the train part of data, we should create a mapping which will help to encode the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sV6QygUw6fcb"
   },
   "outputs": [],
   "source": [
    "target_md = train.groupby('major_discipline').target.sum()\n",
    "count_md = train.groupby('major_discipline').target.count()\n",
    "\n",
    "original_columns = train.columns\n",
    "train['major_discipline_loo_encoded'] = (train.major_discipline.map(target_md) - train.target) / (train.major_discipline.map(count_md) - 1)\n",
    "map_major_discipline = train.groupby('major_discipline').major_discipline_loo_encoded.mean()\n",
    "\n",
    "train.drop('major_discipline', axis=1, inplace=True)\n",
    "train.rename(columns={'major_discipline_loo_encoded': 'major_discipline'}, inplace=True)\n",
    "train = train[original_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sQmH1y-d9qOW"
   },
   "source": [
    "Let's encode feature `'company_size'` with Catboost encoding using the implementation from `category_encoders` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PfmCVKRx6hHl"
   },
   "outputs": [],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "\n",
    "cbe_encoder = CatBoostEncoder(handle_missing='return_nan')\n",
    "cbe_encoder.fit(train.company_size, train.target)\n",
    "\n",
    "train.company_size = cbe_encoder.transform(train.company_size, train.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lBE4sCLL9uV4"
   },
   "source": [
    "Let's encode feature `'company_type'` with Weight of Evidence (WoE) encoding. A category $x_{ij}$ will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\ln\\left(\\frac{\\mathbb{P}\\left(x_{ij}\\mid y=1\\right)}{\\mathbb{P}\\left(x_{ij}\\mid y=0\\right)}\\right)\\quad.\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=1\\right) = \\frac{\\text{count}\\left(y=1\\mid x_{ij}\\right)}{\\text{count}\\left(y=1\\right)}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=0\\right) = \\frac{\\text{count}\\left(y=0\\mid x_{ij}\\right)}{\\text{count}\\left(y=0\\right)}\n",
    "$$\n",
    "\n",
    "The notation means the following:\n",
    "\n",
    "* $\\text{count}\\left(y=1\\mid x_{ij}\\right)$ denotes the number of observations with the category $x_{ij}$ where the target value is equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\mid x_{ij}\\right)$ denotes the same but for the target value $0$;\n",
    "* $\\text{count}\\left(y=1\\right)$ denotes the number of observations with the target value equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\right)$ denotes the same but for the target value $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A52TWXmH6igK"
   },
   "outputs": [],
   "source": [
    "P_1 = train[train.target == 1].groupby('company_type').target.count() / train[train.target == 1].target.count()\n",
    "P_0 = train[train.target == 0].groupby('company_type').target.count() / train[train.target == 0].target.count()\n",
    "\n",
    "map_company_type = np.log(P_1 / P_0)\n",
    "train.company_type = train.company_type.map(map_company_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wFwADkfU9wxD"
   },
   "source": [
    "Now all the categorical features are encoded. Next, I drop `'enrollee_id'` because it is not a representative feature. After this, I split train part of data into the dataframe which contains only features (without target) and the target array.\n",
    "\n",
    "Before training the models, we should impute the remaining missing values. You might have noticed that I didn't impute missing values for the features `'major_discipline'`, `'company_size'` and `'company_type'`. This is because the number of missing values in these features is relatively big. Let's perform the imputation using KNN approach - where we impute missing values by looking at the similar observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1610996515882,
     "user": {
      "displayName": "Evgeny Kovalev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapCcPAzYLJE2xqpH7xgS8qtR8bZrkCgbHm27oLg=s64",
      "userId": "07828702499945486090"
     },
     "user_tz": -180
    },
    "id": "eCz_Pr_xoa82",
    "outputId": "1457ef28-3783-488e-ea52-fc79f2e6f893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19158, 16), (19158,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YvfwLqvS6kKr"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "knn_imputer.fit(X_train, y_train)\n",
    "\n",
    "X_train = pd.DataFrame(knn_imputer.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-2T2a78d90mJ"
   },
   "source": [
    "Finally, let's train a Random Forest classifier from `sklearn` on the train data and check feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g4_1694F6l0Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'major_discipline'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=8, random_state=13)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "impotance_list = clf.feature_importances_\n",
    "index_max = max(range(len(impotance_list)), key=impotance_list.__getitem__)\n",
    "X_train.columns[index_max]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sUydmtoi92d8"
   },
   "source": [
    "Finally, let's process the test data performing the similar operations as for the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "veC-y23Fwe8L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2129, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.experience = test.experience.fillna(-1)\n",
    "test.education_level = test.education_level.map(map_education)\n",
    "test.relevent_experience = test.relevent_experience.map(map_relevent_experience)\n",
    "\n",
    "df_gender_te = pd.get_dummies(test.gender)\n",
    "df_gender_te.columns = ['gender-' + column for column in df_gender_te.columns]\n",
    "test = pd.concat([test, df_gender_te], axis=1)\n",
    "test.drop('gender', axis=1, inplace=True)\n",
    "\n",
    "df_enrolled_university_te = pd.get_dummies(test.enrolled_university)\n",
    "df_enrolled_university_te.columns = ['enrolled_university-' + column for column in df_enrolled_university_te.columns]\n",
    "test = pd.concat([test, df_enrolled_university_te], axis=1)\n",
    "test.drop('enrolled_university', axis=1, inplace=True)\n",
    "\n",
    "test.city = test.city.map(map_city)\n",
    "test.last_new_job.fillna(-1, inplace=True)\n",
    "test.last_new_job = test.last_new_job.map(map_last_new_job)\n",
    "test.experience = test.experience.map(map_experience)\n",
    "test.major_discipline = test.major_discipline.map(map_major_discipline)\n",
    "test.company_size = cbe_encoder.transform(test.company_size, test.target)\n",
    "test.company_type = test.company_type.map(map_company_type)\n",
    "\n",
    "X_test = test.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_test = test['target']\n",
    "X_test = pd.DataFrame(knn_imputer.transform(X_test), columns=X_test.columns)\n",
    "X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the operations above, I obtained `X_test` with a shape (2129, 16). Let's calculate the predictions of the trained Random Forest model on it and check the accuracy of the predictions on test data. And then calculate the predictions of the same model on `X_train` and check the accuracy there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_te = clf.predict(X_test)\n",
    "y_pred_tr = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yM1CI29I6rv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "round(accuracy_score(y_test, y_pred_te), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(accuracy_score(y_train, y_pred_tr), 2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO77HBmz1/PpQ55VCcYPEhx",
   "collapsed_sections": [],
   "name": "Week1_practice.ipynb",
   "provenance": [
    {
     "file_id": "1WztG2ZwKA0bx5LJIEQNQH23OULDBBmt8",
     "timestamp": 1610996564372
    }
   ]
  },
  "coursera": {
   "schema_names": [
    "categorical-data-task-week-1-1"
   ]
  },
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d9a420dd7d9958c9bfab5a33c6b672d78ee78f6ceacdd75e61df641f7a5961d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
